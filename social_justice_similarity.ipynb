{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file explores if determining sensitivity by measuring the similarity of the input word to one or more social justice buzzword works. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                                           ability\n",
      "1                                       able-bodied\n",
      "2                                           ableism\n",
      "3      Aboriginal and Torres Strait Islander People\n",
      "4                                         Afrikaner\n",
      "                           ...                     \n",
      "171                                 white supremacy\n",
      "172                                       Whiteness\n",
      "173                                  whitesplaining\n",
      "174                                            woke\n",
      "175                                            yeke\n",
      "Name: lemma, Length: 176, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Get words from macht.sprache\n",
    "import pandas as pd\n",
    "input_words_en_de = pd.read_json('macht.sprache_words.json')\n",
    "\n",
    "\n",
    "input_words_en = input_words_en_de[input_words_en_de['lemma_lang'] == 'en']['lemma'].reset_index(drop=True)\n",
    "input_words_de = input_words_en_de[input_words_en_de['lemma_lang'] == 'de']['lemma'].reset_index(drop=True)\n",
    "print(input_words_en)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Using pre-trained GloVe Twitter 25 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up lexicon\n",
    "import gensim.downloader as api\n",
    "glove_vectors = api.load(\"glove-twitter-25\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input word:  ancestors\n",
      "--- buzzword similarities ---\n",
      "    similar_word  buzzword_similarity\n",
      "1         slaves             0.576186\n",
      "19          jews             0.513533\n",
      "16      believed             0.475029\n",
      "7   commandments             0.458929\n",
      "6        priests             0.420096\n",
      "0       prophets             0.411606\n",
      "5         unborn             0.401501\n",
      "13       orphans             0.401005\n",
      "8         greeks             0.398529\n",
      "17     glorified             0.388898\n",
      "11    sacrificed             0.370196\n",
      "3   missionaries             0.365527\n",
      "4       worships             0.359310\n",
      "10       witches             0.354220\n",
      "18     egyptians             0.334991\n",
      "14   forefathers             0.326398\n",
      "9    worshippers             0.323238\n",
      "2      disciples             0.309377\n",
      "12    worshipped             0.290851\n",
      "15      apostles             0.231268\n"
     ]
    }
   ],
   "source": [
    "input_word = input_words_en.iloc[7]  # The word you want to find similar words for\n",
    "n = 20  # The number of most similar words you want\n",
    "print(\"input word: \", input_word)\n",
    "\n",
    "# Find the n most similar words to the specified word\n",
    "most_similar_words = glove_vectors.most_similar(input_word, topn=n)\n",
    "\n",
    "# Print the most similar words and their similarity scores\n",
    "#print(\"--- most similar words ---\")\n",
    "#for similar_word, similarity in most_similar_words:\n",
    "#    print(f\"{similar_word}: {similarity}\")\n",
    "\n",
    "\n",
    "\n",
    "# Rank the list of similar words according to their similarity to a buzzword \n",
    "buzzword_similarities = []\n",
    "buzzwords = ['discrimination', 'power', 'political']\n",
    "\n",
    "print(\"--- buzzword similarities ---\")\n",
    "for similar_word, _ in most_similar_words:\n",
    "    similarity = 0\n",
    "    for buzzword in buzzwords:\n",
    "        similarity = similarity + glove_vectors.similarity(similar_word, buzzword)\n",
    "    buzzword_similarities.append((similar_word, similarity/len(buzzwords)))\n",
    "    \n",
    "    \n",
    "df = pd.DataFrame(buzzword_similarities, columns=['similar_word', 'buzzword_similarity'])   \n",
    "df.sort_values(by=['buzzword_similarity'], ascending=False, inplace=True) \n",
    "print(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Using self-trained word2vec model on reddit comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "\n",
    "# Load pre-trained Word2Vec model.\n",
    "w2v = gensim.models.Word2Vec.load(\"word2vec_test.model\").wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input word:  ancestors\n",
      "--- buzzword similarities ---\n",
      "   similar_word  buzzword_similarity\n",
      "10  forefathers             0.447843\n",
      "4          mede             0.432698\n",
      "18       iranic             0.414727\n",
      "16      seljuks             0.409344\n",
      "15    sumerians             0.396964\n",
      "11       serers             0.388622\n",
      "17    anatolian             0.383567\n",
      "3         medes             0.367793\n",
      "12      afghans             0.364946\n",
      "14   decendents             0.360088\n",
      "2       mongols             0.349856\n",
      "13        herat             0.349758\n",
      "9      persians             0.346132\n",
      "8   descendents             0.345633\n",
      "6         avars             0.344050\n",
      "7     assyrians             0.338645\n",
      "19       persia             0.301108\n",
      "1     descended             0.286256\n",
      "5      ancestor             0.238327\n",
      "0   descendants             0.232567\n"
     ]
    }
   ],
   "source": [
    "input_word = input_words_en.iloc[7]  # The word you want to find similar words for\n",
    "n = 20  # The number of most similar words you want\n",
    "print(\"input word: \", input_word)\n",
    "\n",
    "most_similar_words = w2v.most_similar(input_word, topn=n)\n",
    "\n",
    "# Print the most similar words and their similarity scores\n",
    "#print(\"--- most similar words ---\")\n",
    "#for similar_word, similarity in most_similar_words:\n",
    "#    print(f\"{similar_word}: {similarity}\")\n",
    "\n",
    "\n",
    "# Rank the list of similar words according to their similarity to a buzzword \n",
    "buzzword_similarities = []\n",
    "buzzwords = ['discrimination', 'power', 'political']\n",
    "\n",
    "print(\"--- buzzword similarities ---\")\n",
    "for similar_word, _ in most_similar_words:\n",
    "    similarity = 0\n",
    "    for buzzword in buzzwords:\n",
    "        similarity = similarity + w2v.similarity(similar_word, buzzword)\n",
    "    buzzword_similarities.append((similar_word, similarity/len(buzzwords)))\n",
    "    \n",
    "    \n",
    "df = pd.DataFrame(buzzword_similarities, columns=['similar_word', 'buzzword_similarity'])   \n",
    "df.sort_values(by=['buzzword_similarity'], ascending=False, inplace=True) \n",
    "print(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wordclouds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
